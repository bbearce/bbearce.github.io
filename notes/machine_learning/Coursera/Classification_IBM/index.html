<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    
    <link rel="shortcut icon" href="../../../../img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>Classification - Ben's Code Journal</title>
    <link href="../../../../css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="../../../../css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="../../../../css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../../css/highlight.css">
    <link href="../../../../css/extra.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="../../../../js/jquery-3.2.1.min.js"></script>
    <script src="../../../../js/bootstrap-3.3.7.min.js"></script>
    <script src="../../../../js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../../../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "Classification", url: "#_top", children: [
              {title: "KNN (K-Nearest Neighbors)", url: "#knn-k-nearest-neighbors" },
              {title: "Classification Accuracy", url: "#classification-accuracy" },
          ]},
          {title: "K-NN Code Example", url: "#k-nn-code-example", children: [
          ]},
        ];

    </script>
    <script src="../../../../js/base.js"></script>
      <script src="../../../../javascripts/mathjax.js"></script>
      <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
  <a name="_top"></a>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../Decision_Trees_IBM/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../Decision_Trees_IBM/" class="btn btn-xs btn-link">
        Decision Trees
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../Intro_and_Regression/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../Intro_and_Regression/" class="btn btn-xs btn-link">
        Intro and Regression
      </a>
    </div>
    
  </div>

    

    <h1 id="classification">Classification</h1>
<p>Source: <a href="https://www.coursera.org/learn/machine-learning-with-python">Machine_Learning_With_Python_IBM</a></p>
<ul>
<li>Supervised learning</li>
<li>Unknown items into discrete categories</li>
<li>
<p>Multiple inputs (values) to predict a single field (output column</p>
</li>
<li>
<p>Decisions trees</p>
</li>
<li>Naive bayes</li>
<li>Linear discriminant analysis</li>
<li>k-Nearsest neighbors</li>
<li>Logistic regression</li>
<li>Neural networks</li>
<li>Support vector machines (SVM)</li>
</ul>
<h2 id="knn-k-nearest-neighbors">KNN (K-Nearest Neighbors)</h2>
<ul>
<li>independent variables: (<span class="arithmatex">\(x_n\)</span>)</li>
<li>target field: dependent var (y) - might have n classes</li>
</ul>
<p>Ex:
<span class="arithmatex">\(x_n\)</span>'s = age and income</p>
<ul>
<li>Literally cluster a bit...maybe 5 nearest neighbors. k is 5.</li>
<li>Classify cases based on their similarity to other cases</li>
<li>Cases that are near each other are said to be neighbors</li>
<li>
<p>Based on similar cases with same class labels are near each other</p>
</li>
<li>
<p>Pick a value for k.</p>
</li>
<li>Calc distance to unknown case from allcases</li>
<li>Select the k-obserservations ,............</li>
<li>Predict the response of the unknown data point using the most poilar responsecale from the K-nearest neighbors</li>
</ul>
<p>Ex:
Customer1 = {age: 34}
Customer2 = {age: 30}</p>
<p><span class="arithmatex">\(Dis(x_1, x_2) = \sqrt{\sum_{i=0}^{n}(x_{1i}-x_{2i})^2}\)</span><br />
<span class="arithmatex">\(Dis(x_1, x_2) = \sqrt{\sum_{i=0}^{n}(34-30)^2}\)</span></p>
<p>2 independent variables:
<span class="arithmatex">\(Dis(x_1, x_2) = \sqrt{\sum_{i=0}^{n}(x_{1i}^<code>-x_{2i}^</code>)^2+(x_{1i}^{<code>}-x_{2i}^{</code>})^2}\)</span>  </p>
<h3 id="so-how-do-we-choose-the-right-k">So, how do we choose the right K?</h3>
<ul>
<li>A low value of K causes a highly complex model and causes overfitting.</li>
<li>A high value is too general.</li>
<li>We're not sure yet... loop over k and test accuracy</li>
</ul>
<h2 id="classification-accuracy">Classification Accuracy</h2>
<p>Compare predictions <span class="arithmatex">\(y\)</span> and actual <span class="arithmatex">\(\hat{y}\)</span> of test data set.</p>
<h3 id="jaccard-index">Jaccard index</h3>
<p><span class="arithmatex">\(J(y, \hat{y}) = \frac{|y\cap\hat{y}|}{|y\cup\hat{y}|} = \frac{|y\cap\hat{y}|}{|y|+|\hat{y}|-|y\cap\hat{y}|}\)</span></p>
<h3 id="f1-score">F1-score</h3>
<ul>
<li>Precision = TP / (TP + FP)</li>
<li>Recall =  TP / (TP + FN)</li>
<li>F1-score = 2x(prc x rec)/(prc + rec)</li>
</ul>
<h3 id="log-loss">Log Loss</h3>
<p>Probability of label versus label itself. Only for binary output. This is related to logistic regression.</p>
<p><span class="arithmatex">\(LogLoss = \frac{1}{n}\sum_{i=1}^{i}(y\log(\hat{y}) +(1-y)*\log(1-\hat{y}))\)</span></p>
<p>Looks like infinity towards 0 for x and 0 for correct prediction with 100% confidence.</p>
<pre><code class="language-bash">(y)
00|.
  | .
  | .
  | .
  |  .
  |   .
  |      .
  |            .
 0|                         .
 ------------------------------(x)
</code></pre>
<h1 id="k-nn-code-example">K-NN Code Example</h1>
<pre><code class="language-bash"># Setup Environment
cd ~/Desktop; mkdir temp; cd temp; pyenv activate venv3.10.4;
# cd ~/Desktop; rm -r temp; # To remove
</code></pre>
<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from sklearn import preprocessing, metrics
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier

df = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%203/data/teleCust1000t.csv')
df.head()
# classes in dataset (customer category)
key = {'1':'Basic Service','2':'E Service','3':'Plus Service','4':'Total Service'}
df['custcat'].value_counts()
# normalize the data
X = df[['region', 'tenure','age', 'marital', 'address', 'income', 'ed', 'employ','retire', 'gender', 'reside']] .values  #.astype(float)
y = df['custcat'].values; y[0:5]
X = preprocessing.StandardScaler().fit(X).transform(X.astype(float)); X[0:5]
# train/test/split
X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)
print ('Train set:', X_train.shape,  y_train.shape)
print ('Test set:', X_test.shape,  y_test.shape)
# k-nearest neighbor
k = 4
# train model and predict  
neigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train); neigh
# predicting
yhat = neigh.predict(X_test); yhat[0:5]
print(&quot;Train set Accuracy: &quot;, metrics.accuracy_score(y_train, neigh.predict(X_train)))
print(&quot;Test set Accuracy: &quot;, metrics.accuracy_score(y_test, yhat))
# practice
k=6 # do over with this k
neigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train); neigh
yhat = neigh.predict(X_test); yhat[0:5]
print(&quot;Train set Accuracy: &quot;, metrics.accuracy_score(y_train, neigh.predict(X_train)))
print(&quot;Test set Accuracy: &quot;, metrics.accuracy_score(y_test, yhat))
</code></pre>
<blockquote>
<p>metrics.accuracy_score is jaccard_score (jaccard index)</p>
</blockquote>
<pre><code class="language-python"># try even more Ks
Ks = 10
mean_acc = np.zeros((Ks-1))
std_acc = np.zeros((Ks-1))

for n in range(1,Ks):
    #Train Model and Predict  
    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)
    yhat=neigh.predict(X_test)
    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat) # jaccards
    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0]) # standard error
    # https://en.wikipedia.org/wiki/Standard_error

mean_acc
std_acc
# plot
plt.plot(range(1,Ks),mean_acc,'g')
plt.fill_between(range(1,Ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)
plt.fill_between(range(1,Ks),mean_acc - 3 * std_acc,mean_acc + 3 * std_acc, alpha=0.10,color=&quot;green&quot;)
plt.legend(('Accuracy ', '+/- 1xstd','+/- 3xstd'))
plt.ylabel('Accuracy ')
plt.xlabel('Number of Neighbors (K)')
plt.tight_layout()
plt.show()
# best accuracy
print( &quot;The best accuracy was with&quot;, mean_acc.max(), &quot;with k=&quot;, mean_acc.argmax()+1) 
</code></pre>

  <br>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../Decision_Trees_IBM/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../Decision_Trees_IBM/" class="btn btn-xs btn-link">
        Decision Trees
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../Intro_and_Regression/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../Intro_and_Regression/" class="btn btn-xs btn-link">
        Intro and Regression
      </a>
    </div>
    
  </div>

    <br>
</div>

<footer class="col-md-12 wm-page-content">
  <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a> using <a href="None">Windmill Dark</a> theme by None (noraj).</p>
</footer>

</body>
</html>